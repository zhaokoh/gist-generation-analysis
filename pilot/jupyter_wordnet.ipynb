{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "\n",
    "This notebook analyse the descriptors generated in pilot with WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import base64\n",
    "import ctypes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>soa</th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im0008010.jpg</td>\n",
       "      <td>67</td>\n",
       "      <td>fish</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im0008010.jpg</td>\n",
       "      <td>67</td>\n",
       "      <td>ampbibians</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im0008010.jpg</td>\n",
       "      <td>67</td>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>im0008010.jpg</td>\n",
       "      <td>67</td>\n",
       "      <td>colorful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im0008010.jpg</td>\n",
       "      <td>67</td>\n",
       "      <td>ocean</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image  soa        word  frequency\n",
       "0  im0008010.jpg   67        fish          2\n",
       "1  im0008010.jpg   67  ampbibians          1\n",
       "2  im0008010.jpg   67        blue          1\n",
       "3  im0008010.jpg   67    colorful          1\n",
       "4  im0008010.jpg   67       ocean          1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gist_word_data = pd.read_csv('actual_word_table.csv', usecols=[\"image\", \"soa\", \"word\", \"frequency\"])\n",
    "gist_word_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"im0001684.jpg\"\n",
    "soa = 67\n",
    "\n",
    "q_criteria = \"image == '\" + image_soa.image + \"' and soa == '\" + str(image_soa.soa) + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: ampbibians has no synset.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import itertools\n",
    "\n",
    "\n",
    "image_soa_set = gist_word_data[['image','soa']].drop_duplicates()\n",
    "\n",
    "# img = \"im0001684.jpg\"\n",
    "# soa = 67\n",
    "# print(gist_word_data.query(\"image == '\" + img + \"' and soa == '\" + str(soa) + \"'\"))\n",
    "\n",
    "for image_soa_index in range(0, image_soa_set.shape[0]):\n",
    "    image_soa = image_soa_set.iloc[image_soa_index,:]\n",
    "    \n",
    "    q_criteria = \"image == '\" + image_soa.image + \"' and soa == '\" + str(image_soa.soa) + \"'\"\n",
    "    result = gist_word_data.query(q_criteria)\n",
    "    \n",
    "    all_synsets = []\n",
    "    for w in result['word']:\n",
    "        synset_names = [];\n",
    "        \n",
    "        if (len(wn.synsets(w)) == 0):\n",
    "            print(\"WARNING: %s has no synset.\" % (w))\n",
    "            continue\n",
    "            \n",
    "        for s in wn.synsets(w):\n",
    "            synset_names.append(s.name())\n",
    "            \n",
    "        all_synsets.append(synset_names)\n",
    "\n",
    "    # Derive all the permutations and find the closest\n",
    "    #print(all_synsets)\n",
    "    \n",
    "    comb_synsets = list(itertools.product(*all_synsets))\n",
    "    \n",
    "    comb_synsets_similarity = []\n",
    "    for cs in comb_synsets:\n",
    "        ind_comb_synsets = list(itertools.combinations(cs, 2))\n",
    "        \n",
    "        total_similarity = 0\n",
    "        for ics in ind_comb_synsets:\n",
    "            sim_score = wn.synset(ics[0]).path_similarity(wn.synset(ics[1]))\n",
    "\n",
    "            if (sim_score != None):\n",
    "                total_similarity = total_similarity + wn.synset(ics[0]).path_similarity(wn.synset(ics[1]))\n",
    "                      \n",
    "        \n",
    "        comb_synsets_similarity.append(comb_synsets_similarity)\n",
    "    break\n",
    "\n",
    "    print(max(comb_synsets_similarity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fish', 'ampbibians', 'blue', 'colorful', 'ocean', 'pretty', 'sea', 'tank', 'water']\n",
      "Processing word: fish\n",
      "Processing word: ampbibians\n",
      "[ERROR] Unable to find a synset for word: ampbibians.\n",
      "Processing word: blue\n",
      "Processing word: colorful\n",
      "Processing word: ocean\n",
      "Processing word: pretty\n",
      "Processing word: sea\n",
      "Processing word: tank\n",
      "Processing word: water\n",
      "Similarity between Synset('fish.n.01') and Synset('fish.n.01'): 1.0000\n",
      "Similarity between Synset('fish.n.01') and Synset('blue.n.01'): 0.0556\n",
      "Similarity between Synset('fish.n.01') and Synset('ocean.n.01'): 0.0769\n",
      "Similarity between Synset('fish.n.01') and Synset('sea.n.01'): 0.0769\n",
      "Similarity between Synset('fish.n.01') and Synset('tank.n.01'): 0.0714\n",
      "Similarity between Synset('fish.n.01') and Synset('water.n.01'): 0.0714\n",
      "Similarity between Synset('blue.n.01') and Synset('fish.n.01'): 0.0556\n",
      "Similarity between Synset('blue.n.01') and Synset('blue.n.01'): 1.0000\n",
      "Similarity between Synset('blue.n.01') and Synset('ocean.n.01'): 0.0833\n",
      "Similarity between Synset('blue.n.01') and Synset('sea.n.01'): 0.0833\n",
      "Similarity between Synset('blue.n.01') and Synset('tank.n.01'): 0.0588\n",
      "Similarity between Synset('blue.n.01') and Synset('water.n.01'): 0.0769\n",
      "Similarity between Synset('colorful.a.01') and Synset('colorful.a.01'): 1.0000\n",
      "Similarity between Synset('ocean.n.01') and Synset('fish.n.01'): 0.0769\n",
      "Similarity between Synset('ocean.n.01') and Synset('blue.n.01'): 0.0833\n",
      "Similarity between Synset('ocean.n.01') and Synset('ocean.n.01'): 1.0000\n",
      "Similarity between Synset('ocean.n.01') and Synset('sea.n.01'): 0.3333\n",
      "Similarity between Synset('ocean.n.01') and Synset('tank.n.01'): 0.0833\n",
      "Similarity between Synset('ocean.n.01') and Synset('water.n.01'): 0.1250\n",
      "Similarity between Synset('pretty.s.01') and Synset('pretty.s.01'): 1.0000\n",
      "Similarity between Synset('sea.n.01') and Synset('fish.n.01'): 0.0769\n",
      "Similarity between Synset('sea.n.01') and Synset('blue.n.01'): 0.0833\n",
      "Similarity between Synset('sea.n.01') and Synset('ocean.n.01'): 0.3333\n",
      "Similarity between Synset('sea.n.01') and Synset('sea.n.01'): 1.0000\n",
      "Similarity between Synset('sea.n.01') and Synset('tank.n.01'): 0.0833\n",
      "Similarity between Synset('sea.n.01') and Synset('water.n.01'): 0.1250\n",
      "Similarity between Synset('tank.n.01') and Synset('fish.n.01'): 0.0714\n",
      "Similarity between Synset('tank.n.01') and Synset('blue.n.01'): 0.0588\n",
      "Similarity between Synset('tank.n.01') and Synset('ocean.n.01'): 0.0833\n",
      "Similarity between Synset('tank.n.01') and Synset('sea.n.01'): 0.0833\n",
      "Similarity between Synset('tank.n.01') and Synset('tank.n.01'): 1.0000\n",
      "Similarity between Synset('tank.n.01') and Synset('water.n.01'): 0.0769\n",
      "Similarity between Synset('water.n.01') and Synset('fish.n.01'): 0.0714\n",
      "Similarity between Synset('water.n.01') and Synset('blue.n.01'): 0.0769\n",
      "Similarity between Synset('water.n.01') and Synset('ocean.n.01'): 0.1250\n",
      "Similarity between Synset('water.n.01') and Synset('sea.n.01'): 0.1250\n",
      "Similarity between Synset('water.n.01') and Synset('tank.n.01'): 0.0769\n",
      "Similarity between Synset('water.n.01') and Synset('water.n.01'): 1.0000\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "print(words)\n",
    "s = []\n",
    "for w in words:\n",
    "    print(\"Processing word: %s\" % (w))\n",
    "    synsets = wn.synsets(w)\n",
    "    \n",
    "    if len(synsets) == 0:\n",
    "        print(\"[ERROR] Unable to find a synset for word: %s.\" % (w))\n",
    "        continue\n",
    "        \n",
    "    s.append(synsets[0])\n",
    "    \n",
    "for ss in s:\n",
    "    for sss in s:\n",
    "        sim = ss.path_similarity(sss)\n",
    "        if sim is None:\n",
    "            continue\n",
    "            \n",
    "        print(\"Similarity between %s and %s: %.4f\" % (ss, sss, ss.path_similarity(sss)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
